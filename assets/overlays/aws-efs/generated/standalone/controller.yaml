# Generated file. Do not edit. Update using "make update".
#
# Loaded from base/controller.yaml
# Applied strategic merge patch overlays/aws-efs/patches/controller_add_driver.yaml
# Applied strategic merge patch common/sidecars/controller_driver_kube_rbac_proxy.yaml
# provisioner.yaml: Loaded from common/sidecars/provisioner.yaml
# provisioner.yaml: Added arguments [--feature-gates=Topology=true --extra-create-metadata=true --timeout=5m --worker-threads=1]
# Applied strategic merge patch provisioner.yaml
# livenessprobe.yaml: Loaded from common/sidecars/livenessprobe.yaml
# livenessprobe.yaml: Added arguments [--probe-timeout=3s]
# Applied strategic merge patch livenessprobe.yaml
#
#

apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    config.openshift.io/inject-proxy: csi-driver
    config.openshift.io/inject-proxy-cabundle: csi-driver
  name: aws-efs-csi-driver-controller
  namespace: ${NAMESPACE}
spec:
  selector:
    matchLabels:
      app: aws-efs-csi-driver-controller
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict-local-volumes: socket-dir
        target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
      labels:
        app: aws-efs-csi-driver-controller
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: aws-efs-csi-driver-controller
              topologyKey: kubernetes.io/hostname
            weight: 100
      containers:
      - args:
        - --endpoint=$(CSI_ENDPOINT)
        - --logtostderr
        - --tags=kubernetes.io/cluster/${CLUSTER_ID}:owned
        - --delete-access-point-root-dir=true
        - --v=${LOG_LEVEL}
        env:
        - name: CSI_ENDPOINT
          value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock
        - name: AWS_SDK_LOAD_CONFIG
          value: "1"
        - name: AWS_CONFIG_FILE
          value: /var/run/aws/auth/credentials
        image: ${DRIVER_IMAGE}
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: healthz
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 3
        name: csi-driver
        ports:
        - containerPort: 10302
          name: healthz
          protocol: TCP
        resources:
          limits:
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 50Mi
        securityContext:
          privileged: true
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /var/run/aws/auth
          name: aws-auth
          readOnly: true
        - mountPath: /var/run/secrets/openshift/serviceaccount
          name: bound-sa-token
          readOnly: true
        - mountPath: /var/lib/csi/sockets/pluginproxy/
          name: socket-dir
      - args:
        - --csi-address=/var/lib/csi/sockets/pluginproxy/csi.sock
        - --http-endpoint=localhost:8212
        - --leader-election
        - --leader-election-lease-duration=${LEADER_ELECTION_LEASE_DURATION}
        - --leader-election-renew-deadline=${LEADER_ELECTION_RENEW_DEADLINE}
        - --leader-election-retry-period=${LEADER_ELECTION_RETRY_PERIOD}
        - --leader-election-namespace=openshift-cluster-csi-drivers
        - --v=${LOG_LEVEL}
        - --feature-gates=Topology=true
        - --extra-create-metadata=true
        - --timeout=5m
        - --worker-threads=1
        env:
        - name: ADDRESS
          value: /var/lib/csi/sockets/pluginproxy/csi.sock
        image: ${PROVISIONER_IMAGE}
        imagePullPolicy: IfNotPresent
        name: csi-provisioner
        resources:
          requests:
            cpu: 10m
            memory: 50Mi
        securityContext:
          privileged: true
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /var/lib/csi/sockets/pluginproxy/
          name: socket-dir
      - args:
        - --secure-listen-address=0.0.0.0:9212
        - --upstream=http://127.0.0.1:8212/
        - --tls-cert-file=/etc/tls/private/tls.crt
        - --tls-private-key-file=/etc/tls/private/tls.key
        - --tls-cipher-suites=${TLS_CIPHER_SUITES}
        - --tls-min-version=${TLS_MIN_VERSION}
        - --logtostderr=true
        image: ${KUBE_RBAC_PROXY_IMAGE}
        imagePullPolicy: IfNotPresent
        name: provisioner-kube-rbac-proxy
        ports:
        - containerPort: 9212
          name: provisioner-m
          protocol: TCP
        resources:
          requests:
            cpu: 10m
            memory: 20Mi
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /etc/tls/private
          name: metrics-serving-cert
      - args:
        - --csi-address=/csi/csi.sock
        - --health-port=10302
        - --v=${LOG_LEVEL}
        - --probe-timeout=3s
        env: []
        image: ${LIVENESS_PROBE_IMAGE}
        imagePullPolicy: IfNotPresent
        name: csi-liveness-probe
        resources:
          requests:
            cpu: 10m
            memory: 50Mi
        securityContext:
          privileged: true
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /csi
          name: socket-dir
      - args:
        - --secure-listen-address=0.0.0.0:9211
        - --upstream=http://127.0.0.1:8211/
        - --tls-cert-file=/etc/tls/private/tls.crt
        - --tls-private-key-file=/etc/tls/private/tls.key
        - --tls-cipher-suites=${TLS_CIPHER_SUITES}
        - --tls-min-version=${TLS_MIN_VERSION}
        - --logtostderr=true
        image: ${KUBE_RBAC_PROXY_IMAGE}
        imagePullPolicy: IfNotPresent
        name: kube-rbac-proxy-8211
        ports:
        - containerPort: 9211
          name: driver-m
          protocol: TCP
        resources:
          requests:
            cpu: 10m
            memory: 20Mi
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /etc/tls/private
          name: metrics-serving-cert
      hostNetwork: true
      initContainers:
      - command:
        - sh
        - -c
        - |
          # Define file path variables
          CREDENTIALS_FILE=/var/run/aws/keys/credentials
          AUTH_CREDENTIALS_FILE=/var/run/aws/auth/credentials
          AWS_ACCESS_KEY_ID_FILE=/var/run/aws/keys/aws_access_key_id
          AWS_SECRET_ACCESS_KEY_FILE=/var/run/aws/keys/aws_secret_access_key

          # If credentials key exists in ebs-cloud-credentials secret, then use it as the auth file
          if [ -e "$CREDENTIALS_FILE" ]; then
              cp "$CREDENTIALS_FILE" "$AUTH_CREDENTIALS_FILE"
              echo "Kubernetes Secret already contains credentials file, copied to the right place: $AUTH_CREDENTIALS_FILE"
              exit 0
          fi

          # Otherwise, make sure the access keys are mounted in the pod...
          if [ ! -e "$AWS_ACCESS_KEY_ID_FILE" ] || [ ! -e "$AWS_SECRET_ACCESS_KEY_FILE" ]; then
              echo "AWS keys not found"
              exit 1
          fi

          # And create an auth file based on those keys
          cat <<-EOF > "$AUTH_CREDENTIALS_FILE"
          [default]
          aws_access_key_id=$(cat "$AWS_ACCESS_KEY_ID_FILE")
          aws_secret_access_key=$(cat "$AWS_SECRET_ACCESS_KEY_FILE")
          EOF
          echo "Kubernetes Secret does not have credentials file, created a fresh one at $AUTH_CREDENTIALS_FILE"
        image: ${TOOLS_IMAGE}
        name: init-aws-credentials-file
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - mountPath: /var/run/aws/keys
          name: aws-keys
          readOnly: true
        - mountPath: /var/run/aws/auth
          name: aws-auth
      nodeSelector:
        node-role.kubernetes.io/master: ""
      priorityClassName: system-cluster-critical
      serviceAccount: aws-efs-csi-driver-controller-sa
      tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
        operator: Exists
      volumes:
      - emptyDir: {}
        name: socket-dir
      - name: metrics-serving-cert
        secret:
          secretName: aws-efs-csi-driver-controller-metrics-serving-cert
      - name: aws-keys
        secret:
          secretName: aws-efs-cloud-credentials
      - emptyDir: {}
        name: aws-auth
      - name: bound-sa-token
        projected:
          sources:
          - serviceAccountToken:
              audience: openshift
              path: token
